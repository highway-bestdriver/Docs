<!-- Template for PROJECT REPORT of CapstoneDesign 2025-2H, initially written by khyoo -->
<!-- 본 파일은 2025년도 컴공 졸업프로젝트의 <1차보고서> 작성을 위한 기본 양식입니다. -->
<!-- 아래에 "*"..."*" 표시는 italic체로 출력하기 위해서 사용한 것입니다. -->
<!-- "내용"에 해당하는 부분을 지우고, 여러분 과제의 내용을 작성해 주세요. -->

# Team-Info
| (1) 과제명 | 프로그래밍 지식이 없는 AI 학습자들을 위한 블록 UI 기반 CNN 딥러닝 모델 제작 플랫폼
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | 14-고속도로위 |
| (3) 팀 구성원 | 김지우 (2171009): 리더, AI/BE, GPT 연동/코드 생성/피드백 생성 기능 개발, DB 관리 <br> 최지원 (2276335): 팀원, FE, 블록 기반 UI 구현, 시각화 기능 및 전체 페이지 구조 설계/개발  <br> 황재령 (2171055) : 팀원, AI/BE, 회원 관리/모델 관리/코드 작동 기능 개발, DB 관리			 |
| (4) 팀 지도교수 | 심재형 교수님 |
| (5) 과제 분류 | 산학과제 |
| (6) 과제 키워드 | AI 모델제작, 블록 neural network layer, 자동 코드 생성  |
| (7) 과제 내용 요약 | 프로그래밍 지식이 없는 AI 학습자들도 쉽게 CNN 모델을 설계하고 학습할 수 있도록 돕는 블록 UI 기반 딥러닝 플랫폼이다. <br>사용자는 TensorFlow나 PyTorch 코드를 작성하지 않고도, 블록을 드래그 앤 드롭하여 Conv2D, Pooling, Dense 같은 레이어를 조합해 CNN 모델을 설계할 수 있다. 설계된 블록 모델은 내부적으로 JSON으로 변환되며, 이를 GPT API에 전달해 실행 가능한 Keras 코드로 자동 생성한다. 생성된 코드는 GPU 환경에서 학습되며, 학습 로그와 결과는 실시간으로 시각화되어 사용자에게 제공된다. 학습이 완료되면, 모델 구조와 결과 데이터를 다시 GPT에 전달해 모델 개선 피드백을 받을 수 있다. 이 과정을 통해 사용자는 코드 작성 없이 딥러닝 모델을 직접 설계·학습·분석할 수 있고, AI의 피드백을 받아 반복적으로 성능을 개선할 수 있다. 이를 통해 코딩에 어려움을 겪는 딥러닝 입문자와 비전공자에게 직관적이고 실습 중심의 학습 환경을 제공하는 효과를 기대할 수 있다. |

<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 | <br><b>Target Customer</b> <br> - AI 이론을 학습했으나 코드를 작성하는데 미숙하여 AI 모델 설계에 어려움을 겪는 사람 <br> - AI 모델 구조를 직관적인 블록 형태로 확인하며 모델 설계 방식을 학습하고 싶은 사람 <br><br>**Pain Points**<br> - 딥러닝 모델 설계에는 높은 수준의 프로그래밍 지식 필요 <br> - 프로그래밍 비전공자 혹은 초보자에게는 코드 기반 모델 제작 및 학습 과정이 AI에 대한 높은 진입 장벽으로 작용함 <br> - AI 이론을 학습하면서도 모델의 전체 구조가 이해되지 않는 이상 학습 효율성이 떨어지고, 직관적으로 모델을 이해하기 위해서는 시각화된 요소가 필요함<br><br> |
| (2) 기존연구와의 비교 | <br>**유사 서비스**<br>1. Google Teachable Machine<br>- 사용자가 데이터를 라벨링하여 입력하면 코드를 입력하지 않고도 자동으로 학습된 모델을 제공함<br>- 한계점: 모델을 직접 설계하거나, layer를 조합해 구성하는 기능은 없음<br>2. Microsoft Lobe<br>- 이미지 분류 모델을 코드를 작성하지 않고 만들 수 있으며, 시각적인 라벨링 및 학습 과정을 제공.<br>- 한계점: 모델의 세부적인 구조 설계 불가능.<br>3. Orange Data Mining, Tableau<br>- 블록 형태로 데이터 전처리, 분석, 시각화를 할 수 있는 노코드 시각화 툴<br>- 한계점: 딥러닝 layer를 쌓아 모델을 직접 구성하는 기능은 없음<br>4. KNIME, RapidMiner<br>- 데이터 분석, 머신러닝 기능을 제공하며 블록 기반 시각적 UI 지원<br>- 한계점: AI 모델 학습 파이프라인은 구성할 수 있으나, CNN 모델이 아닌 머신러닝 모델 위주이기 때문에 CNN layer 단위의 모델 구조 설계 기능은 없음. <br><br>**본 서비스와의 차별점**<br>1. 모델 설계 방식: 사용자가 직접 Conv, Pooling, Dense와 같은 딥러닝 레이어를 블록처럼 조립하여 모델 구조를 직관적으로 설계할 수 있음<br>2. GPT 기반 코드 자동 생성: 사용자가 설계한 블록 구조를 기반으로 GPT에 전달하여, 실행 가능한 tensorflow 코드를 자동으로 생성<br>3. AI 피드백: 학습이 완료된 후 모델 구조 및 성능을 GPT에 다시 전달하여, 해당 모델의 개선 피드백 제공<br>4. 비전공자/코딩 초보 타겟: 프로그래밍에 익숙하지 않은 AI 학습자, 비전공 입문자 등을 위해 딥러닝 진입 장벽을 낮추어 설계됨 <br><br>**결론**<br>- 기존 서비스들은 대부분 데이터 분석이나 머신러닝 파이프라인 시각화에 초점을 맞추고 있으며, 딥러닝 모델 제작 기능이 있는 경우에도 주로 사용자 데이터를 기반으로 모델이 자동 생성되는 형태에 그친다. 반면, 본 서비스는 사용자가 직접 딥러닝 레이어를 블록 형태로 조립하여 모델을 설계함으로써, 딥러닝 구조에 대한 직관적인 이해를 돕고 각 레이어의 역할을 깊이 있게 학습할 수 있도록 설계되었다. 또한, 설계된 모델을 GPT를 통해 하드코딩 없이 학습 가능한 코드로 자동 변환하므로, 더 유연하고 실용적인 딥러닝 교육 플랫픔으로서 기존 서비스 대비 높은 차별성과 교육적 가치를 지닌다.<br><br>|
| (3) 제안 내용 | <br> **제안 1. 블록 기반 모델 설계 기능**<br>- CNN 레이어(Conv2D, MaxPooling, Dense 등) 블록 생성<br>- 드래그 앤 드롭으로 블록 배치 및 연결<br>- 각 레이어의 하이퍼파라미터를 커스텀하여 설정<br><br>**제안2. 모델 학습 결과 반환 기능**<br>- 블록으로 제작된 모델이 GPU 환경에서 실행되고 학습 중인 과정을 확인<br>- 반환된 학습 결과(accuracy, loss 등)을 확인<br><br>**제안3. 시각화 된 학습 결과**<br>- Accuracy, loss, IoU 등의 그래프를 사용자 인터페이스에서 확인<br><br>**제안4. GPT API 기반 모델 개선 피드백**<br>- 학습 결과와 모델 구조를 기반으로 GPT가 제공하는 모델 개선 피드백 확인<br>- 에러 발생 시 에러문을 기반으로 GPT가 모델 구조 개선 방향 제시<br><br>본 프로젝트는 프로그래밍에 익숙하지 않은 AI 학습자들을 위해 딥러닝 모델을 직관적으로 설계하고 학습할 수 있는 블록 기반 CNN 모델 제작 플랫폼을 제안한다. 먼저 새로운 프로젝트를 생성하면 사용자는 데이터셋을 직접 선택하고, 학습에 적용할 전처리의 종류와 값을 설정한다. 그 후 모델 설계 단계에서는 Conv, Pooling, Dense 등의 레이어를 블록 형식의 UI로 화면 상에서 조립하고 하이퍼파라미터 등의 값을 설정하여 모델을 설계할 수 있으며, 내부적으로는 해당 구조가 JSON 데이터 형태로 변환된다. 이 과정에서 사용자는 코딩을 하지 않고도 AI 모델을 스스로 구현해볼 수 있게 된다. 이 JSON 데이터는 GPT API를 통해 tensorflow 코드로 자동 변환되며, 생성된 코드는 서버의 GPT 환경에서 직접 학습된다. 서버에서 반환된 학습 로그는 사용자 화면에 실시간으로 시각화되고, 학습 완료 후에는 모델 구조 및 성능 데이터를 바탕으로 GPT가 개선 피드백을 제공한다. 이를 확인한 사용자는 설정값을 변경해보거나 레이어 순서, 값 등을 바꿔보는 실습을 통해 딥러닝 구조와 동작 원리를 효과적으로 학습할 수 있다. 만약 레이어 블록 설계에 문제가 있을 경우, GPT가 도출된 에러문을 바탕으로 블록 설계의 개선 방향을 제공한다.<br><br> |
| (4) 기대효과 및 의의 | <br>본 서비스는 코딩에 대한 진입 장벽을 낮춘 딥러닝 교육 플랫폼을 제공하여 비전공자 및 AI 입문자가 딥러닝 모델 설계 및 학습 과정을 쉽게 체험할 수 있도록 한다. 사용자는 직접 모델을 구성하고 학습 결과를 시각적으로 확인하며, LLM(AI)으로부터 모델 개선 및 분석 피드백까지 받을 수 있어 이론과 실습이 통합된 학습을 할 수 있다. 이를 통해 인공지능 교육의 접근성과 효율성을 동시에 향상시키고, 더 많은 사람들이 AI에 대해 쉽고 깊이 있게 이해할 수 있는 기회를 제공한다.<br><br> |
| (5) 주요 기능 리스트 | <br>**1. 블록 기반 모델 설계 UI**<br>- 사용자는 웹 화면에서 CNN 모델의 구성 요소(Conv, Pooling, Flatten, Dense 등)를 블록 형태로 선택하여 드래그 앤 드롭으로 설계할 수 있다. 블록 간 연결을 통해 모델의 구조를 정의하며, 각 블록은 설정 창을 통해 필터 수, 커널 크기, 활성화 함수 등 하이퍼파라미터를 설정할 수 있다.<br>- Customer View: 프로그래밍 지식이 없는 사용자도 블록 조립만으로 직관적으로 모델을 설계할 수 있으며, 레이어 간 연결 구조를 시각적으로 이해하고 학습할 수 있다.<br><br>**2. 블록 구조 → JSON 변환**<br>- 사용자가 UI 상에서 설계한 모델 구조를 내부적으로 일관된 JSON 포맷으로 변환하는 기능. 각 블록(레이어)은 해당 타입과 필요한 파라미터 정보를 포함한 딕셔너리 형태로 변환되며, 전체 모델은 리스트 형태로 저장된다.<br>ex) 예시 JSON 구조<br> <br><br>**3. JSON → 코드 자동 생성**<br>- JSON으로 표현된 모델 구조를 OpenAI GPT API에 전달하여, 해당 모델 구조에 맞는 학습 가능한 tensorflow 코드로 자동 변환하는 기능. GPT는 JSON 구조를 기반으로 레이어 순서, 파라미터 설정,  모델 클래스 정의, 필요한 함수 등을 자동으로 작성하여 반환한다. <br>ex) <br><GPT 프롬프트 예시><br>아래 JSON 구조에 맞게 실행 가능한 tensorflow 코드를 작성해주세요. 만약 구조적 오류가 있다면 오류 메세지를 반환하여주세요.<br>{<br>"model_name": <br>"MyCNN",<br>"dataset_name": "MNIST",<br>"layers": [...],<br>"preprocessing": […],<br> "hyperparameters: […],<br>}<br><응답 예시> - 실행 가능한 tensorflow 코드 or python 파일<br>import tensorflow as tf<br>from tensorflow.keras.layers import Input, Conv2D, AveragePooling2D, Flatten, Dense, ReLU<br>from tensorflow.keras.models import Model<br>def myCNNModel():<br>….<br><br>**4. 생성된 코드 실행 및 모델 학습**<br>- GPT가 생성한 모델 코드를 서버 측에서 자동 실행하여 모델을 학습시키는 기능. 코드 실행은 컨테이너 같은 환경에서 수행되며, 학습에는 GPU가 활용된다.<br>- Customer View: 사용자는 블록 설계 → 코드 생성 → 학습까지 전 과정을 몇 번의 클릭만으로 수행 가능<br>*-Celery worker는 해당 코드 파일을 받아 학습 task를 실행하고, Redis를 통해 프론트엔드에 학습 로그를 실시간으로 publish함.<br> -실행 환경<br> - 학습은 Celery worker가 실행 중인 컨테이너에서 수행되며, 필요 시 GPU 자원이 연결됨 <br> - 학습 스크립트 실행 중 stdout 로그를 실시간 수집하고, 로그 내에 특정 포맷({"type": "log", ...})으로 포함된 메시지를 프론트에서 실시간 표시 <br> - Redis Pub/Sub 활용 <br> - 로그 출력은 Redis Pub/Sub 구조를 통해 실시간 전파되며, 프론트엔드에서는 해당 채널을 구독하고 그래프를 실시간 렌더링함*<br>**5. 학습 로그 및 결과 시각화**<br>- 학습 도중 또는 완료 후 손실 함수 변화,  accuracy, confusion matrix 등의 로그 및 성능 지표를 시각화하여 사용자에게 실시간 또는 결과 형태로 제공한다.<br>- 시각화 항목: Epoch별 Accuracy / Loss 그래프, Confusion Matrix, 모델 구조 요약<br>- Customer View: 자신이 만든 모델의 학습 결과를 그래프와 같은 시각적 요소 확인하며, AI 모델 동작 원리, 레이어 별 역할, 하이퍼파라미터의 영향 등에 대한 이해를 높인다.<br><br>**6. 모델 개선 피드백**<br>- 학습이 완료된 후, 모델 구조 및 성능 결과를 GPT에게 다시 전달하여 모델 개선 방향, 추천 레이어, 하이퍼파라미터 조정 등의 최종적인 피드백을 자동으로 받는 기능. <br>- Customer View: 단순한 실행 결과만 확인할 수 있는 것을 넘어, AI로부터 사용자에게 모델 개선 방향을 제시 받아 심도 있는 학습이 가능하다.<br>ex)<br><GPT 프롬프트 예시><br>이 모델의 accuracy는 0.54, loss은 0.39입니다. 다음은 모델 구조입니다. 어떻게 개선하면 좋을까요?<br>- Conv2D → MaxPooling → Flatten → Dense(128) → Dense(10)<br><GPT 응답 피드백 예시><br>- “Dropout 레이어를 추가해 과적합을 방지해보세요.”<br>- “Conv2D 레이어 수를 늘려보세요.”<br>- “배치 정규화를 적용하면 학습 속도가 개선될 수 있습니다.”<br><br> |

<br>

# Project-Design & Implementation
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | **[설계 모델]** <br>- 블록 기반 모델 설계 UI: 드래그 앤 드롭 기반 레이어 구성 UI, 각 블록별 하이퍼파라미터 설정 기능 포함 (ex. Conv2D 필터 수 설정)<br>- 모델 구조 → JSON 변환 : UI에서 정의된 모델을 JSON으로 변환 및 저장<br>- 코드 실행 및 학습 :  컨테이너 기반 실행 환경에서 생성된 코드 자동 실행 및 학습<br>- 학습 결과 시각화 : Accuracy, Loss 등 시각화<br>- 모델 개선 피드백 : 학습 결과를 바탕으로 GPT 기반 자동 피드백 제공<br><br> **[UI 분석/설계 모델]** <br>- 블록 디자인 에디터 화면<br>- 코드 미리보기<br>- 학습 상태 및 결과 시각화 패널<br>- 모델 피드백 패널<br><br> **[DB 설계 모델]** <br>- 모델 저장 테이블: 모델 이름, JSON 구조, 생성일, 사용 데이터셋 등<br>- 학습 기록 테이블: accuracy, loss, epoch 별 기록, 학습 완료 여부, 수정 여부 등 |
| (2) 전체 시스템 구성 | <img width="400" src="https://github.com/user-attachments/assets/f85c8722-6580-46fa-ac43-2a5d8a978307"/><br>  **<외부 모듈 및 오픈소스>**<br>- Next.js: 사용자 인터페이스 제공, 블록 기반 UI, 로그인, 모델 학습 요청, 결과 시각화, 인터랙션<br>- FastAPI: 사용자 인증 처리, 모델 JSON 저장, GPT API 연동, 코드 실행, DB 관리<br>-GPT API: 모델 구조(JSON) 기반 tensorflow 코드 자동 생성, 학습 완료 후 개선 피드백 생성<br>-Docker: 전체 시스템을 컨테이너 기반으로 실행 및 배포, 생성된 코드 파일을 Docker 컨테이너 내에서 실행, GPU 사용 지원.<br>- SQLAlchemy: 데이터베이스 ORM 관리<br>- Alembic: DB 마이그레이션<br>- OpenAI GPT API: 코드 자동 생성, 모델 피드백 생성<br>- Tensorflow: 모델 학습 및 실행 프레임워크<br>- JWT, OAuth2: 사용자 인증 및 권한 관리<br>- matplotlib/seaborn: 학습 결과 시각화<br>*-Celery & Redis : 비동기 분산 작업 처리* |
| (3) 주요엔진 및 기능 설계 | - 블록 모델 설계 엔진: Docker 기반 코드 실행 서버 <br> - JSON 변환 엔진: 블록 구조를 순회하며 JSON 스펙에 맞춰 직렬화 수행 <br> - GPU 프롬프트 엔진: JSON 구조를 GPT에 적합한 형태로 가공, 오류 핸들링 포함 <br> - 코드 실행 엔진: 생성된 코드 파일을 Docker 컨테이너 내에서 실행, GPU 사용 지원 <br> - 시각화 엔진: epoch 별 accuracy, loss 등 시각화, 학습 완료 후 즉시 제공 <br> - 피드백 생성기: 학습 결과와 모델 구조를 기반으로 GPT에 피드백 요청. 구조 개선 팁 또는 하이퍼파라미터 추천 제공 <br> - *비동기 학습 실행 엔진 (Celery + Redis): <br>   • FastAPI는 사용자로부터 학습 요청을 수신한 뒤, 요청 정보를 Celery task로 큐에 등록하고 즉시 응답 반환 <br>   • *Celery Worker*는 *Redis 큐*에서 task를 수신 후 생성된 Python 학습 코드를 실행하여 학습 진행 <br>   • 학습 중 출력되는 로그는 Redis Pub/Sub로 실시간 스트리밍되어 프론트에 표시됨 <br>   • 학습 완료 후 결과는 DB에 저장되고, GPT 피드백 요청도 자동 수행됨* <br><br> **1. FE(NextJS):** 사용자 인터페이스 제공, 블록 기반 모델 설계, 로그인, 모델 학습 요청, 결과 시각화 <br> - 레이어 블록 드래그 앤 드롭 UI, 파라미터 입력 <br> - 모델 설계 JSON 생성 <br><br> **2. BE(FastAPI):** 사용자 인증 처리, 모델 JSON 저장, GPT API 연동, 코드 실행, DB 관리 <br> - 인증/사용자 관리 (JWT, Google OAuth) <br> - 모델 설계 JSON 저장 <br> - GPT 호출(OpenAI) - 코드 자동 생성, 모델 성능 분석 및 피드백 <br> - 모델 학습 실행 <br> - 학습 결과 시각화 & 피드백 <br><br> **3. GPT API:** 모델 구조(JSON) 기반 tensorflow 코드 자동 생성, 학습 완료 후 개선 피드백 생성 <br> - 모델 JSON 구조 → tensorflow 코드 생성 <br><br> **4. DB (MySQL):** 사용자 정보, 모델 구조, 학습 결과, 피드백 등의 모든 데이터 저장 및 조회 처리 <br> - 사용자 정보 <br> - 모델 구조/설계 정보 <br> - 변환된 tensorflow 코드 <br> - 학습 성능 <br> - GPT 피드백 <br><br> **5. Docker:** 전체 시스템을 컨테이너 기반으로 실행 및 배포 <br> - 백엔드(FastAPI), 프론트엔드(React), MySQL DB, 학습 서버 등을 각각 Docker 컨테이너로 구성 <br> - 서비스 간 연동 및 환경 설정 일괄 관리 <br> - 개발 및 배포 환경 간 일관성 유지 <br> - 각 서비스 의존성 및 실행 환경 관리 |
| (4) 주요 기능의 구현 | **1) 블록 기반 모델 설계 UI**<br>- 사용자는 웹 화면에서 CNN 모델의 구성 요소(Conv, Pooling, Flatten, Dense 등)를 블록 형태로 선택하여 드래그 앤 드롭으로 설계할 수 있다. 블록 간 연결을 통해 모델의 구조를 정의하며, 각 블록은 설정 창을 통해 필터 수, 커널 크기, 활성화 함수 등 하이퍼파라미터를 설정할 수 있다.<br>- 기술 스택: React.js, React Flow 라이브러리<br>- UI 구성<br>* 레이어 선택 영역: Conv2D, MaxPooling, Dense, Flatten 등의 블록을 선택할 수 있는 패널<br>* 드래그 앤 드롭 영역: 모델 블록을 순서대로 배치하여 CNN 구조 설계<br>* 속성 설정 창: 각 블록을 클릭하면 filters, kernel size, activation 등 하이퍼파라미터 설정 입력창 표시<br>- 데이터 흐름<br>* 사용자가 블록을 배치하면 내부적으로 JSON 구조로 자동 동기화<br>* 각 블록은 고유 ID를 가지고 있어 시퀀스 및 구조 추적 가능<br><br>**2) 블록 구조 → JSON 변환**<br>- 사용자가 UI 상에서 설계한 모델 구조를 내부적으로 일관된 JSON 포맷으로 변환하는 기능. 각 블록(레이어)은 해당 타입과 필요한 파라미터 정보를 포함한 딕셔너리 형태로 변환되며, 전체 모델은 리스트 형태로 저장된다.<br>- 각 블록의 type, 설정값, 순서가 key-value 형태로 구성됨<br>- 백엔드 전송:  FastAPI 백엔드로 POST 요청 시 위 구조 전체가 전달됨<br>ex) 예시 JSON 구조<br>{<br>"model_name": "MyCNNModel",<br>"dataset_name": "MNIST",<br>  "layers": […],<br>  "preprocessing": {…},<br>"hyperparameters": {…}<br>}<br><br>**3) JSON → 코드 자동 생성**<br>- JSON으로 표현된 모델 구조를 OpenAI GPT API에 전달하여, 해당 모델 구조에 맞는 학습 가능한 tensorflow 코드로 자동 변환하는 기능. GPT는 JSON 구조를 기반으로 레이어 순서, 파라미터 설정,  모델 클래스 정의, 필요한 함수 등을 자동으로 작성하여 반환한다. <br>- 사용 API: OpenAI GPT-4o<br>- 프롬프트 설계<br>  * 시스템 메시지: *“You are a helpful assistant that writes Pytorch code from model JSON.”<br>  * 사용자 메시지: “아래 JSON 구조에 따라 PyTorch 모델 정의 및 데이터 전처리 코드를 작성해줘.<br>요구사항: <br> 1. 모델 정의 <br> - `layers` 필드는 사용자가 만든 모델 구조로, 각 항목은 하나의 레이어를 의미함. <br> - `type`: 레이어 타입 (예: "Conv2d", "ReLU", "BatchNorm2d", ...) <br> - `name`: 레이어 이름 (코드에서 self.에 들어갈 이름)<br> - `inputs`: 이전 레이어의 이름 (str 또는 List[str]) → 이걸 따라 forward() 내에서 연결해야 함<br> - `SequentialLayer`는 내부에 하위 레이어를 나열함 (layers 필드 사용)<br> 2. 데이터 전처리<br> - `preprocessing`은 torchvision.transforms.v2 기반의 전처리 리스트임<br> - `SequentialTransform`은 Compose처럼 동작함<br> - 최종적으로 transforms = v2.Sequential([...]) 형태로 생성해야 함<br> 3. 코드 형식<br> - PyTorch `nn.Module` 클래스를 사용해서 `class Net(nn.Module):`으로 정의해<br> - `__init__()`에서는 self.conv1 = ... 식으로 레이어 선언<br> - `forward()`에서는 `inputs`를 따라 레이어를 연결해<br> - 데이터셋은 torchvision.datasets 사용 가능<br> - 출력은 실행 가능한 전체 코드로 작성 (exec 가능해야 함)<br> - `model`, `x_train`, `y_train`, `x_test`, `y_test`는 모두 코드 내에서 정의되어야 함<br> - 학습 (`fit`, `optimizer`, `loss`)은 작성하지 말 것<br> {…. JSON 구조…}”* <br> * 구조 파싱 실패 시 프론트에서 사용자에게 경고 메세지 띄우기<br>- 응답 처리<br>   * GPT 응답에서 코드만 추출해 generate_code 테이블에 저장<br>   * 사용자는 코드를 미리보기 혹은 .py 파일로 다운 가능<br>*3-1)레이어 오류 검출<br> 사용자가 블록 기반으로 설계한 CNN 모델을 기반으로 GPT가 PyTorch 코드를 생성할 때, 코드 실행 전에 발생할 수 있는 모델의 구성 및 파라미터 유효성을 사전 검증하는 구조를 설계하였다. 이를 통해 코드 실행 전 단계에서의 런타임 오류를 사전에 방지하고, 사용자 경험의 안정성을 확보할 수 있다. 주요 검출 항목은 다음과 같다.<br>오류 1. 각 레이어의 필수 파라미터 누락 검출<br> 각 레이어 별 파라미터는 name, placeholder 필드를 가진 객체로 이루어져 있다. 여기에 필수 파라미터인 경우, required 필드가 true로 저장되어 있어 다음 step으로 넘어가기 위한 버튼 클릭 시 유효성 검증 로직이 작동한다. GPT 코드 생성을 트리거하기 전에 모든 블록의 파라미터 리스트를 순회하여 required가 true인 필드에 대해 undefined, 빈 문자열, null 등의 입력 누락 여부를 검증하는 방식으로 확인한다. 누락이 있을 경우 다음 단계로 넘어갈 수 없도록 버튼을 비활성화 처리한다. 이러한 방식은 Zustand로 구성된 전역 상태 저장소 내의 블록 리스트를 순회하는 단일 함수로 구현하였다.<br>오류 2. 파라미터 입력 타입 불일치 오류<br>각 레이어 별 파라미터의 입력 타입으로 가능한 모든 경우들이 객체 형식으로 리스트업 되어 저장되어있다. 입력 타입이 정해져 있는 파라미터인 경우 해당 타입명을 객체 필드에 추가해주어 블록의 설정 정보를 저장하는 시점에 유효성을 검증하도록 하였다. 사용자가 입력한 값은 기본적으로 문자열이므로, 설정 저장 시점에 해당 문자열이 명시된 type으로 파싱이 가능한지 여부를 검증한다. 만약 타입에 옳지 않은 입력값이 들어왔을 경우 alert를 제공하여 유저에게 타입 재확인을 요구한다.<br> 오류 3. inputs 연결 오류 - 레이어끼리의 순환 발생<br> 모든 레이어는 하나 이상의 입력(inputs)을 통해 선행 레이어와 연결되어야 하며, 이 연결 관계는 방향성 있는 그래프(DAG; Directed Acyclic Graph)의 형태를 가져야 한다. 하지만 사용자가 순환적인 연결(예: A → B → C → A)을 설정한 경우, 모델이 무한 루프에 빠질 수 있으며 이는 실행 불가능한 구조를 초래하지만, 코드를 실행하는 중에는 오류를 검출하지 못한다. 따라서 이러한 순환 오류를 사전에 방지하기 위해, 모델 내 레이어 간의 연결 관계를 그래프 형태로 구성한 후 Topological Sort 알고리즘을 적용하여 DAG 여부를 검증하였다. 레이어 수와 방문한 노드 수가 일치하지 않는 경우, 내부에 순환이 존재하는 것으로 간주하고 오류 메시지를 사용자에게 반환한다.<br> 예) “입력: conv1 → conv2 → conv3 → conv1” → <br> 검출 결과: “Cycle detected among layer inputs: conv1 → conv2 → conv3 → conv1” <br>이를 통해 구조적으로 유효하지 않은 모델이 실행되기 전에 오류를 사전 차단할 수 있다. <br>3-2) 코드 실행 중 오류 발생<br>다음은 실행 중에 검출되는 오류에 대한 처리다.<br>오류 1. 입출력 shape / 채널 수 불일치<br>사용자가 설계한 CNN 구조에서 Conv2d, Linear, BatchNorm2d 등의 레이어는 각각 입력의 채널 수나 텐서의 shape에 대한 명확한 조건을 가진다.<br>예를 들어 Conv2d(in_channels=64)는 정확히 64채널을 입력으로 받아야 하며, Linear(in_features=1024)는 입력 텐서의 마지막 차원이 1024여야 한다.<br> 하지만 GPT가 자동으로 생성한 코드에서는 이전 레이어의 출력 크기를 정확히 계산하지 못하고 in_features나 in_channels를 잘못 설정하는 경우가 존재한다. 이 경우에는 코드 실행 중 PyTorch가 다음과 같은 형태의 오류를 발생시킨다:<br>“RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x512 and 1024x10)”<br>”RuntimeError: Given groups=1, weight of size [64, 3, 3, 3], expected input[1, 1, 28, 28] to have 3 channels, but got 1 channels instead”<br>이를 검출하기 위해, 모델 코드를 exec()를 통해 실행한 뒤 dummy input (예: torch.randn(1, 3, 224, 224))을 전달하고, forward() 과정에서 발생하는 에러 메시지를 수집한다. 해당 에러 메시지에 "mat1 and mat2 shapes cannot be multiplied" 또는 "expected input to have" 등의 문자열이 포함되어 있는 경우, 이는 shape 또는 채널 수 불일치로 판단하고 자동으로 분류한다.<br>3-3) JSON 구조 - 실행 코드 레이어 일치 여부 검증<br>사용자가 블록 기반으로 설계한 모델은 내부적으로 JSON 구조로 표현되며, 이는 각 레이어의 type, name, inputs, 그리고 파라미터(in_channels, kernel_size, ...)를 포함한다. <br>GPT는 해당 JSON을 기반으로 PyTorch 코드를 생성하게 되는데, 이 때 코드 내의 레이어 정의가 원본 JSON 구조와 정확히 일치하는지에 대한 검증이 필요하다.<br> 이를 위해, 다음과 같은 정적 분석 기법을 적용하였다.<br>1. AST(추상 구문 트리) 파싱: GPT가 생성한 PyTorch 코드를 Python AST로 파싱하여 self.conv1 = nn.Conv2d(...) 형태의 모든 레이어 정의를 추출한다.<br> 2. 레이어 이름 및 타입 비교: 추출된 레이어의 이름과 타입을 JSON의 레이어 목록과 비교하여 누락 여부, 타입 불일치 여부를 판별한다.<br>3. 파라미터 정합성 검증: in_channels, kernel_size 등 주요 파라미터가 JSON과 일치하는지 비교한다.<br>예시 결과:<br>- conv1:  일치<br>- fc1: JSON에 있음, 코드에 없음 (정의 누락)<br>- bn1: num_features=64 → 코드에서는 num_features=32 (파라미터 불일치)<br>이러한 분석을 통해 GPT가 생성한 코드가 사용자의 설계와 논리적으로 완전하게 대응하고 있는지를 자동으로 판단할 수 있으며, 검증 실패 시 해당 레이어를 중심으로 문제를 사용자에게 피드백하도록 구현하였다.*<br>**4) 생성된 코드 실행 및 모델 학습**<br>- GPT가 생성한 모델 코드를 서버 측에서 자동 실행하여 모델을 학습시키는 기능. 코드 실행은 컨테이너 같은 환경에서 수행되며, 학습에는 GPU가 활용된다.<br>- 코드 실행 환경<br>* 실행 전 GPT 응답 코드를 .py 파일로 저장한 뒤 docker 컨테이너 내부에서 실행 <br>* 컨테이너는 GPU가 장착된 환경에서 tensorflow가 설치된 이미지로 구성<br>- 학습 결과 저장<br>* 학습 로그 (accuracy, loss 등) 및 모델 성능을 training_logs 테이블에 저장<br>* 실행 시 stdout과 stderr 로그를 파일로 수집하고, epoch별 학습 결과(accuracy, loss)를 JSON 파일로 추출<br>- 오류 처리<br>* 코드 실행 중 오류 발생 시 해당 오류를 GPT에 넘겨 코딩 초보자인 사용자가 이해 가능한 수준의 피드백 생성<br><br>**5) 학습 로그 및 결과 시각화**<br>- 학습 도중 또는 완료 후 손실 함수 변화,  accuracy, confusion matrix 등의 로그 및 성능 지표를 시각화하여 사용자에게 실시간 또는 결과 형태로 제공한다.<br>- 시각화 항목: Epoch별 Accuracy / Loss 그래프, Confusion Matrix, 모델 구조 요약<br>- 기술 스택<br>* FE: 시각화된 이미지 혹은 Chart.js로 그래프 실시간 출력<br>* BE: Matplotlib, Seaborn으로 이미지 생성<br>- 데이터 처리 방식<br>(1) 학습 코드 내에서 로그 수집 → JSON 파일 or DB 저장<br>(2) 백엔드에서 처리 후 시각화 결과를 프론트로 반환|
| (5) 기타 | **1) 확장성 고려** <br>- 추후 LSTM, Transformer 등 다양한 모델 블록 추가 기능<br>- 사용자 정의 레이어 지원 고려<br>- 학습 외 평가 기능 (예를 들어, 테스트 이미지 예측 기능) 추가 가능<br><br>**2) 보안 및 안정성** <br>- GPT API 오류 및 학습 실패 대비 재시도 로직 구현<br>- 사용자별 작업 세션 분리, 코드 실행 샌드박스 환경 적용  |

<br>
